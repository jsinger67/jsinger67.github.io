<!DOCTYPE HTML>
<html lang="en" class="light sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>The Parol Parser Generator</title>
        <meta name="robots" content="noindex">


        <!-- Custom HTML head -->

        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->

        <!-- MathJax -->
        <script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

        <!-- Provide site root to javascript -->
        <script>
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="toc.js"></script>
    </head>
    <body>
    <div id="body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            var sidebar = null;
            var sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
            }
            sidebar_toggle.checked = sidebar === 'visible';
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="toc.html"></iframe>
            </noscript>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">The Parol Parser Generator</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <!-- markdownlint-disable first-line-h1 -->
<!-- markdownlint-disable Inline HTML -->
<br>
<img src="./Parol.svg" alt="Logo" height=150 with=150>
<br><br><br>
<!-- markdownlint-enable Inline HTML -->
<!-- markdownlint-enable first-line-h1 -->
<h1 id="the-parol-parser-generator"><a class="header" href="#the-parol-parser-generator">The <code>parol</code> Parser Generator</a></h1>
<p><a href="https://github.com/jsinger67/parol"><code>parol</code></a> is a parser generator with some unique characteristics.</p>
<p>It is an installable command line tool that can generate complete parsers from a single grammar
description file. <code>parol</code> is also a library that you can use in your own crates.</p>
<p>Using a builder API it is easy to integrate the code generation process into your crate's build
process via a cargo build script (<code>build.rs</code>).</p>
<p><code>parol</code> can be instructed to infer and generate all AST data types that you would otherwise have to
design yourself. <code>parol</code> can do this simply by analyzing your language's grammar description.</p>
<p>You can control the process of AST type generation in two ways. Firstly, you can mark elements for
omission in your AST. Secondly, you can specify your own types for language elements, which are then
inserted at the right position into the resulting AST type.</p>
<p>Language description and language implementation is strictly separated in <code>parol</code>. Thus, you can
design your language's grammar without any need to process anything because generated parsers
function by default as acceptors. This allows you to do <strong>real rapid prototyping</strong> of your grammar.</p>
<p><code>parol</code> generates a trait as interface between your language processing and the generated parser.
The trait contains functions for each non-terminal of your grammar which you can implement for
non-terminals you need to process. In the simplest case you only implement the trait function for
the start symbol of your grammar which is called after the whole input string is parsed. This
function then is called with a parameter that comprises the complete structure of the parsed
document.</p>
<p>The parser calls the interface trait's functions via a separately generated adapter automatically
during the process of parsing.</p>
<p><code>parol</code> now provides a whole ecosystem of tools including an
<a href="https://github.com/jsinger67/parol/tree/main/tools/parol-vscode">Extension</a> for Visual Studio Code
and a <a href="https://github.com/jsinger67/parol/tree/main/crates/parol-ls">Language Server</a>.</p>
<p>As of version 0.24.0 generated parsers can recover from syntax errors automatically. This means that
the parser usually does not stop parsing the input after the first syntax error occurs, and
instead tries to synchronize with the input in order to continue the analysis accordingly.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="history-of-this-project"><a class="header" href="#history-of-this-project">History of this project</a></h1>
<p>The <code>parol</code> Parser Generator started as a personal journey to master LL(k) parsing with the concise
means of deterministic finite automata.</p>
<p>Basic influence on its design had two parser generators which could not be more contrary in their
approaches</p>
<ul>
<li>The classic Unix tool Yacc resp. <a href="https://www.gnu.org/software/bison/">Bison</a></li>
<li><a href="https://www.antlr.org/">ANTLR</a></li>
</ul>
<p>But both of them have their own quirks and idiosyncrasies.</p>
<p>Bison tends to generate mysterious shift/reduce or reduce/reduce conflicts which can be sometimes
hard to understand and ANTRL generates recursive descending parsers which are prone to stack
overflows. It is easy to write (or generate) a program that crashes a parser generated by ANTLR.</p>
<p>On the other hand Bison generates deterministic parsers which are terse actually by using finite
automata and ANTLR solves the problem of choosing the next production for a certain non-terminal by
utilizing deterministic finite automata too.</p>
<p>So why not have the best of both worlds?</p>
<p>With this goal in mind I started my first attempts using F# as programming language
(<a href="https://github.com/jsinger67/Lelek">Lelek</a>).
But finally I stopped working on this project because it didn't feel 'right' anymore.</p>
<p>Anyhow, Lelek was a necessary step for me to become confident about what is feasible and what is
not.</p>
<p>A lot of attempts followed and I made a shift to Rust which felt more vibrant and compelling to me.</p>
<p>And so <code>parol</code> was born - actually as a rewrite of Lelek. But I was willing to jettison some parts
of Lelek and replace them with new approaches.</p>
<p>What I took over:</p>
<ul>
<li>The basic approach of using regexes to generate scanners</li>
<li>Using DFAs to solve the
<a href="https://github.com/jsinger67/Lelek/blob/master/docs/Approach.md">Rule Decision Problem</a>, although I
changed the way to obtain the k-sets for productions</li>
<li>The basic ideas behind the structure of the grammar description language -  and their resemblance
to Bison's input format</li>
<li>The separation of language description and language implementation</li>
<li>The strategy to check a grammar first for some preconditions before trying to generate data for a
parser to guarantee the termination of certain algorithms</li>
<li>The algorithm for <a href="https://github.com/jsinger67/id-tree-layout">visualizing parse trees</a></li>
</ul>
<p>What I changed:</p>
<ul>
<li>The part of recursion detection</li>
<li>The part of generating k-sets for productions (roughly all algorithms FIRST(k), FOLLOW(k))</li>
<li>The overall wording is hopefully more precise - e.g. I prefer 'Production' over 'Rule' now</li>
<li>The <a href="https://github.com/jsinger67/parol_runtime">parser runtime</a> was separated as a small crate</li>
</ul>
<p>What I added:</p>
<ul>
<li>Infer and generate all types of the grammar's AST, so your grammar description is sufficient for
<code>parol</code> to build a completely functioning acceptor with no extra effort - this is <strong>real rapid
prototyping</strong> for your language!</li>
<li>Built-in tools for
<ul>
<li>generating new crates</li>
<li>checking a grammar for certain properties (left-recursion, reachability, productivity)</li>
<li>left-factoring of a given grammar</li>
<li>calculating FIRST(k) and FOLLOW(k) sets</li>
<li>generating random sentences of a given grammar description</li>
</ul>
</li>
<li>Scanner states, aka
<a href="https://www.cs.princeton.edu/~appel/modern/c/software/flex/flex_toc.html#TOC11">Start conditions</a></li>
<li>Build script integration to invoke <code>parol</code> automatically during the build of your own crate</li>
<li>An <a href="https://github.com/jsinger67/parol/tree/main/tools/parol-vscode">extension</a> for Visual Studio
Code and a <a href="https://github.com/jsinger67/parol/tree/main/crates/parol-ls">Language Server</a></li>
<li>The possibility to use LALR(1) grammars optionally instead of LL(k) ones</li>
<li>And all those features Lelek never received</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="getting-started"><a class="header" href="#getting-started">Getting started</a></h1>
<h2 id="installation"><a class="header" href="#installation">Installation</a></h2>
<p>Before you can use <code>parol</code> you have to install it.</p>
<p>Since <code>parol</code> generates Rust code it is assumed that you have a Rust toolchain installed. Otherwise
head over to <a href="https://rustup.rs/">Rustup</a> or <a href="https://www.rust-lang.org/tools/install">Install Rust</a>
first.</p>
<p><code>parol</code> only needs stable Rust.</p>
<p>Now you should be able to install <code>parol</code> on your platform:</p>
<pre><code class="language-shell">cargo install parol
</code></pre>
<p>To confirm a correct installation invoke this command:</p>
<pre><code class="language-shell">$ parol -V
parol 0.10.6
</code></pre>
<p>If you see an error saying the tool couldn't be found please check your PATH variable. It should
include ~/.cargo/bin.</p>
<h3 id="the-video"><a class="header" href="#the-video">The video</a></h3>
<p>If you prefer a more visual introduction, I recommend watching the introductory
<a href="https://youtu.be/TJMwMqD4XSo">video</a> on YouTube.</p>
<h2 id="let-parol-generate-a-crate-for-you"><a class="header" href="#let-parol-generate-a-crate-for-you">Let <code>parol</code> generate a crate for you</a></h2>
<p>We can use the <code>parol new</code> subcommand and let <code>parol</code> create our new project for us.</p>
<pre><code class="language-shell">parol new --bin --path ./my_grammar
</code></pre>
<p>Then change into the new project's folder and start the initial build. Here <code>parol</code> is generating
two files from the initial grammar definition.</p>
<pre><code class="language-shell">cd ./my_grammar
cargo build
</code></pre>
<p>And run the test with the generated parser:</p>
<pre><code class="language-shell">$ cargo run ./test.txt
    Finished dev [unoptimized + debuginfo] target(s) in 0.20s
     Running `target\debug\my_grammar.exe ./test.txt`
Parsing took 4 milliseconds.
Success!
MyGrammar { my_grammar: Token { symbol: "Hello world!", token_type: 5, location: Location { line: 4, column: 5, length: 12, start_pos: 0, pos: 97, file_name: "./test.txt" } } }
</code></pre>
<p><code>parol</code> has generated a full fledged parser with AST types suitable for your grammar description!</p>
<p>Now you can open your favorite editor</p>
<pre><code class="language-shell">code .
</code></pre>
<p>and adapt the grammar description in the file <code>my_grammar.par</code> to fit your requirements. Any
subsequent invocations of <code>cargo build</code> will trigger <code>parol</code> to generate the derived sources
automatically if the grammar description file <code>my_grammar.par</code> has been changed.</p>
<p><strong>This is all you need to set up a working development environment.</strong></p>
<blockquote>
<h2 id="vs-code-extension-and-language-server"><a class="header" href="#vs-code-extension-and-language-server">VS Code extension and Language Server</a></h2>
<p>I provide a VS Code extension <a href="https://github.com/jsinger67/parol/tree/main/tools/parol-vscode">parol-vscode</a>.</p>
<p>Please install this extension from VS Code
<a href="https://marketplace.visualstudio.com/items?itemName=jsinger67.parol-vscode">marketplace</a>.
It provides syntax highlighting, folding and language icons and will surely be useful for you.</p>
<p>The extension utilizes a <a href="https://github.com/jsinger67/parol/tree/main/crates/parol-ls">Language Server</a> that you have
to install separately.</p>
<pre><code class="language-shell">cargo install --force parol-ls
</code></pre>
</blockquote>
<div style="break-before: page; page-break-before: always;"></div><h1 id="the-syntax-of-parols-grammar-description"><a class="header" href="#the-syntax-of-parols-grammar-description">The syntax of <code>parol</code>'s Grammar description</a></h1>
<p>I provide the definition of the PAR grammar in PAR grammar <a href="https://github.com/jsinger67/parol/blob/main/crates/parol/src/parser/parol.par">itself</a>.</p>
<p>This grammar is quite concise and most programmers should be familiar with it. But there are several
specialties which will be described here. First please notice the built-in support for language
comments.</p>
<p>Using the <code>%line_comment</code> and <code>%block_comment</code> constructs you can easily define your language's
comments. For example you can define comments like it's done in the calc example
<code>calc.par</code>:</p>
<pre><code class="language-parol">%line_comment "//"
%block_comment  "/\*" "\*/"
</code></pre>
<p>You can supply more than one of these two comment declarations. They will all be considered as valid
comments.</p>
<p>As opposed to EBNF you use C-like line comments starting with two slashes (//) and bock comments
(/* ... */) in PAR files. This is a result of the close relationship between PAR grammar and
bison's grammar.</p>
<blockquote>
<p>As of version 0.22.0 <code>parol</code> doesn't simply discard language comments. They are provided during
parse process via a new method <code>&lt;UserType&gt;GrammarTrait::on_comment_parsed</code> which is called for each
single comment in order of their appearance each time before the parser consumes a normal token from
token stream.</p>
<p>The method is default implemented and the user have to provide an own implementation if she is
interested in language comments.</p>
<p>This is a minimal support but can greatly improve the usability. Also note that this comment
handling is currently only supported in <code>parols</code>'s auto-generation mode.</p>
<p>Any feedback is appreciated.</p>
</blockquote>
<h2 id="defining-the-grammar-type"><a class="header" href="#defining-the-grammar-type">Defining the grammar type</a></h2>
<p>In the global header section you can define the grammar type you want to use in your grammar
description.</p>
<p>The default grammar type is LL(k) and can be omitted.</p>
<pre><code class="language-parol">%grammar_type 'LL(k)'
</code></pre>
<p>You have to option to use LALR(1) grammar type this way.</p>
<pre><code class="language-parol">%grammar_type 'LALR(1)'
</code></pre>
<p>The support of the new grammar type is still in a phase of improvement. If there are any obstacles
here, you can be sure that they will be soon got out of the way.</p>
<h2 id="case-sensitivity"><a class="header" href="#case-sensitivity">Case sensitivity</a></h2>
<p>Non-terminals are treated case sensitive, i. e. "list" and "List" are different symbols. But it is
not encouraged to rely on this in your grammar definition. It is much better to keep a consistent
style on casing in your description.</p>
<h2 id="sections"><a class="header" href="#sections">Sections</a></h2>
<p><code>parols</code>'s input language consists of two sections divided by the <code>%%</code> token. Above there are
declarations of which only the first <code>%start</code> declaration is mandatory. It declares the start symbol
of your grammar.
The second section below the <code>%%</code> token contains the actual grammar description in form of several
productions. At least one production must exist.</p>
<h2 id="the-start-symbol"><a class="header" href="#the-start-symbol">The start symbol</a></h2>
<p>It is important to note that the start symbol of the grammar must always be declared with the
<code>%start</code> declaration. It is the very first declaration in the PAR file.</p>
<pre><code class="language-parol">%start Grammar
</code></pre>
<h2 id="scanner-control"><a class="header" href="#scanner-control">Scanner control</a></h2>
<!-- markdownlint-disable no-inline-html -->
<p>A scanner (aka lexer) is automatically created from all used terminal symbols. Terminal symbols can
also be associated with different scanner states. See section
<a href="ParGrammar.html#scanner-states">Scanner states</a> below for more details.</p>
<!-- markdownlint-enable no-inline-html -->
<h3 id="newline-handling"><a class="header" href="#newline-handling">Newline handling</a></h3>
<p>The scanner per default skips newlines automatically. To suppress this use the <code>%auto_newline_off</code>
directive.
With this you have to handle newline tokens on your own in your grammar.</p>
<h3 id="whitespace-handling"><a class="header" href="#whitespace-handling">Whitespace handling</a></h3>
<p>The scanner also per default skips whitespace automatically. To suppress this use the <code>%auto_ws_off</code>
directive.
With this you have to handle whitespace tokens on your own in your grammar.</p>
<h3 id="terminal-name-generation"><a class="header" href="#terminal-name-generation">Terminal name generation</a></h3>
<p>The names of the terminals are deduced from the content of the terminal itself. For instance, for a
terminal ":=" it creates the terminal name "ColonEqu", see generated parser for Oberon-0. If you
want this name to be more expressive, you can dedicate a separate production to the terminal, lets
say:</p>
<pre><code class="language-parol">Assign: ":=";
</code></pre>
<p>With this trick you define a so called "primary non-terminal for a terminal" (I coined it this way)
that instructs the name generation to name the terminal "Assign".</p>
<h3 id="terminal-representation"><a class="header" href="#terminal-representation">Terminal representation</a></h3>
<p>As of version 0.14.0 <code>parol</code> supports three different styles of terminal representations, all of
them being valid and allowed.</p>
<ul>
<li>The legacy syntax (<code>"..."</code>). These terminals are treated as if they were regular expressions.</li>
<li>New single quoted string literals (<code>'..'</code>) are literal or raw strings. The user doesn't need to
escape any regex meta character. This is used when you don't want to deal with regexes and only use
plain text. E.g.: <code>BlockBegin: '{'</code></li>
<li>New regular expression strings (<code>/../</code>), behaves exactly like the old double quoted string but
better conveys the intent. E.g.: <code>Digits: /[\d]+/</code></li>
</ul>
<p>Internally <code>parol</code> creates scanners on the basis of the Rust regex crate and all terminals are
embedded in a regular expression eventually. You should be aware of this if you get strange errors
from regex generation and want to understand the problem.</p>
<p>Here is an example for a terminal in regular expression form:</p>
<pre><code class="language-parol">AddOperator: /\+|-/;
</code></pre>
<h3 id="terminal-conflicts"><a class="header" href="#terminal-conflicts">Terminal conflicts</a></h3>
<ul>
<li>In case of conflicts between different terminals <em>the first seen will win</em></li>
</ul>
<p>The last point needs a more detailed explanation.
It's best to show an example for such a situation.
Say you have two terminals "-" and "--", <em>minus</em> and <em>decrement</em>. The generated scanner is then
based on the following regular expression:</p>
<pre><code class="language-regexp">/-|--/
</code></pre>
<p>The Rust regex will now match two times <em>minus</em> when actually a <em>decrement</em> operator should be
detected.
It behaves here differently than a classic scanner/lexer like Lex that obeys the <em>longest match</em>
strategy.</p>
<p>Fortunately there is a simple way to achieve what we want. We just need a resulting regular
expression with a different order:</p>
<pre><code class="language-regexp">/--|-/
</code></pre>
<p>This will perfectly do the job.</p>
<p>To get such an order the <em>decrement</em> terminal has to be defined <strong>before</strong> the <em>minus</em> terminal as
in the following snippet.</p>
<pre><code class="language-parol">decrement: /--/
;
...
minus: /-/
;
</code></pre>
<p>Thats all.</p>
<p>With this simple but effective means you have the control over terminal conflicts.</p>
<h3 id="terminals-that-matches-an-empty-string"><a class="header" href="#terminals-that-matches-an-empty-string">Terminals that matches an empty string</a></h3>
<p>Please note that terminals should always match non-empty text portions. This means that you have to
avoid terminals like this:</p>
<pre><code class="language-parol">/a?/, /a*/, /\b/
</code></pre>
<p>Internally the tokenizer will enter a loop and match the empty string over and over again without
making progress in the input. Currently there is no check for this scenario in <code>parol_runtime</code>.</p>
<p>There is a <strong>workaround</strong> when you simply need possibly empty tokens, at least for the <code>?</code> and <code>*</code>
ones.
Make the token <code>+</code> and put their uses in optional expressions <code>[]</code>. This makes them non-empty and
also their possible emptiness explicit for the grammar:</p>
<pre><code class="language-parol">RuleWithWhiteSpaces: WhiteSpaces;
WhiteSpaces: /[ \t]*/;

// =&gt;

RuleWithWhiteSpaces: [ WhiteSpaces ];
WhiteSpaces: /[ \t]+/;
</code></pre>
<!-- markdownlint-disable no-inline-html -->
<h2 id=scanner-states>Scanner states</h2>
<!-- markdownlint-enable no-inline-html -->
<p><code>Parol</code> supports <strong>multiple scanner states</strong>. This feature is known from Flex as
<a href="https://www.cs.princeton.edu/~appel/modern/c/software/flex/flex_toc.html#TOC11">Start conditions</a>
and provides more flexibility in defining several scanners for several parts of your grammar.</p>
<p><code>Parol</code> provides two different ways to control scanner states directly within your grammar
description thereby holding the principle of strict separation of grammar description and grammar
processing in semantic actions. This means no scanner switching in your code, but in the grammar
description. Only because of this rapid prototyping is possible.</p>
<h3 id="the-default-scanner-state-initial"><a class="header" href="#the-default-scanner-state-initial">The Default scanner state INITIAL</a></h3>
<p>INITIAL is the name of the default scanner state 0. Its behavior is defined with <code>ScannerDirectives</code>
in the global <code>Declaration</code> section, such as:</p>
<pre><code class="language-parol">%line_comment "//"
%block_comment "/\*" "\*/"
</code></pre>
<h3 id="introduce-new-scanner-states-with-the-scanner-directive"><a class="header" href="#introduce-new-scanner-states-with-the-scanner-directive">Introduce new scanner states with the %scanner directive</a></h3>
<p>Use the <code>%scanner Name {...}</code> construct after the global <code>Declaration</code> section and before the <code>%%</code>
sign to introduce arbitrary scanner states. The identifier following the %scanner token defines the
name of the state which is used to refer to it from scanner state lists at terminals.</p>
<pre><code class="language-parol">%scanner String {
    %auto_newline_off
    %auto_ws_off
}

%scanner Pragma {
    %block_comment "\{" "\}"
}
</code></pre>
<p>You can place any of the <code>ScannerDirectives</code> within the block that defines the scanner state.</p>
<p>By default each scanner handles (and skips) whitespace and newlines. Use <code>%auto_newline_off</code> and
<code>%auto_ws_off</code> to modify each scanner state appropriately.</p>
<p>Associate terminals with scanner states by prefixing them with a list of comma separated state names
in angle brackets. Like this:</p>
<pre><code class="language-parol">StringDelimiter
    : &lt;String, INITIAL&gt;/"/
    ;
</code></pre>
<p>Scanner state references in different occurrences of the same terminal are accumulated. I.e.,</p>
<pre><code class="language-parol">&lt;State1&gt;"term"
...
&lt;State2&gt;"term"
</code></pre>
<p>will result in</p>
<pre><code class="language-parol">&lt;State1, State2&gt;"term"
</code></pre>
<p>Terminals without explicitly associated scanner state are implicitly associated with scanner state
INITIAL.</p>
<h3 id="parser-bases-scanner-switching"><a class="header" href="#parser-bases-scanner-switching">Parser-bases scanner switching</a></h3>
<p>The first way to control scanner states is to define switching directives within your productions.
This way can only be used for LL(k) grammars because the parser has full knowledge about which
production to handle next when certain input has been encountered from left to right.</p>
<p>Parser-bases scanner state switching is initiated within your productions like in the following two
examples:</p>
<pre><code class="language-parol">String: StringDelimiter %sc(String) StringContent StringDelimiter %sc();

</code></pre>
<p>or</p>
<pre><code class="language-parol">String: StringDelimiter %push(String) StringContent StringDelimiter %pop();

</code></pre>
<p>The <code>%sc</code> instruction is used to switch directly to the state named in the parentheses. The INITIAL
state can be omitted as seen in the second occurrence of the first example, i.e. <code>%sc()</code> and
<code>%sc(INITIAL)</code> are equivalent.</p>
<p>The <code>%push</code> instruction is used to push the index of the current scanner on the internal scanner
stack and to switch to a scanner configuration with the given index in parentheses.</p>
<p>The <code>%pop</code> instruction is used to pop the index of the scanner pushed before and to switch to the
scanner configuration with that index.</p>
<blockquote>
<p>Note that <code>%push</code> and <code>%pop</code> instructions should be balanced. This means that in one context use
<strong>only one</strong> of the combinations <code>%push(S1)</code>/<code>%pop</code> and <code>%sc(&lt;S1&gt;)</code>/<code>%sc(&lt;S2&gt;)</code>. <code>%push</code>/<code>%pop</code>
provides a (call) stack semantics over scanner states whereas <code>%sc</code>/<code>%sc</code> can be used to represent
scanner state graphs semantics. Mixing both semantics should be avoided or at should least be
carefully considered.</p>
</blockquote>
<blockquote>
<p>Currently the scanner parser-based state switching only works if the lookahead
<strong>at the point where the switch is made</strong> is only of size 1 because the lookahead mechanism is
directly influenced by the current scanner state. This means the provision of lookahead tokens will
be made with the current active scanner and may fail if a token is not known by it. In most cases
this can be circumvented by an appropriate grammar formulation. If this is not possible consider to
use <code>Scanner-bases scanner switching</code> instead.</p>
</blockquote>
<p>You may have look at example <code>scanner_states</code> that demonstrates the handling of scanner states.</p>
<h3 id="scanner-bases-scanner-switching"><a class="header" href="#scanner-bases-scanner-switching">Scanner-bases scanner switching</a></h3>
<p>LR grammars reduce the parser stack from the right side and thus you can't decide the scanner state
switching from the perspective of the parser. The tokens are already read and pushed on the parse
stack before it can be decided what production to reduce on them. This means scanner state switching
must work different here.
When incorporating the scanner state switching into the scanner itself the state can be chosen as
early as possible solely from the current state the scanner is in and the token read next.
The good new is that this kind of scanner switching works for LL parsers too and most LL(k) grammars
can be adopted to use scanner-based scanner switching.</p>
<p>Scanner-based scanner switching is defined solely in the header of the grammar file right where the
scanners are defined.</p>
<p>You use the <code>%on</code> and <code>%enter</code> directives to control it (snippets taken from the <code>basic</code> example):</p>
<pre><code class="language-parol">%on Rem %enter Cmnt
%on If, AssignOp, Print %enter Expr

%scanner Cmnt {
    %auto_newline_off
    %on EndOfLine %enter INITIAL
}
%scanner Expr {
    %auto_newline_off
    %on Then, Goto, EndOfLine %enter INITIAL
}
</code></pre>
<p>After the <code>%on</code> directive you can name a list of primary non-terminals which only contain the
terminal like this:</p>
<pre><code class="language-parol">Rem : 'REM'^;
</code></pre>
<p>After the <code>%enter</code> directive you name the target scanner state.</p>
<p>You also may have look at examples <code>scanner_states_lr</code> for a simple demonstration and at example
<code>basic</code> for a more advanced one.</p>
<blockquote>
<p><em>Be aware that mixing of both parser-bases and scanner-based scanner state switching in one grammar
file is not allowed and will result in errors.</em></p>
</blockquote>
<h2 id="omitting-grammar-symbols-from-the-ast-in-auto-gen-modus"><a class="header" href="#omitting-grammar-symbols-from-the-ast-in-auto-gen-modus">Omitting grammar symbols from the AST in auto-gen modus</a></h2>
<p>You can suffix grammar symbols (terminals and non-terminals) with a cut operator (^). This instructs
<code>parol</code> to not propagate them to the AST in auto-gen modus.</p>
<pre><code class="language-parol">Group: '('^ Alternations ')'^;
</code></pre>
<p>The AST type for the symbol <code>Group</code> will then only contain a member for the non-terminal
<code>Alternations</code>. The parentheses are left out.</p>
<h2 id="assigning-user-types-to-grammar-symbols"><a class="header" href="#assigning-user-types-to-grammar-symbols">Assigning user types to grammar symbols</a></h2>
<p>You can specify a user type to be inserted into the AST structure at the place where the symbol
would otherwise had the originally generated type.
Add after a grammar symbol a colon followed by a user type name to instruct <code>parol</code> to use this type
instead. In your language implementation you have to provide fallible conversions from references of
the original generated types (<code>&amp;T</code>) to your types (<code>U</code>) by implementing the trait
<code>TryFrom&lt;&amp;T&gt; for U</code>.</p>
<p>An examples can be found in the <code>list_auto</code> example.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>impl&lt;'t&gt; TryFrom&lt;&amp;Token&lt;'t&gt;&gt; for Number {
    type Error = anyhow::Error;

    fn try_from(number: &amp;Token&lt;'t&gt;) -&gt; std::result::Result&lt;Self, Self::Error&gt; {
        Ok(Self(number.text().parse::&lt;u32&gt;()?))
    }
}
<span class="boring">}</span></code></pre></pre>
<p>You can also define aliases for the user type names by inserting as many <code>%user_type</code> directives as
you want.</p>
<pre><code class="language-parol">%user_type Number = crate::list_grammar::Number
</code></pre>
<p>Then use these aliases behind the colons.</p>
<pre><code class="language-parol">Num: "0|[1-9][0-9]*": Number;
</code></pre>
<h2 id="semantic-actions"><a class="header" href="#semantic-actions">Semantic actions</a></h2>
<p>Semantic actions are strictly separated from your grammar description.
You will use a generated trait with default implementations for each production of your grammar. You
can implement this trait in your grammar processing item and provide concrete implementations for
those productions you are interested in.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="operator-precedence"><a class="header" href="#operator-precedence">Operator precedence</a></h1>
<p>Operator precedence is realized by means of grammar definition.
In other words you put higher prioritized elements into sub-categories. Using this approach you
force the parser to branch into those first which leads to earlier evaluation in the end.</p>
<p>Please have a look at this example:</p>
<pre><code class="language-parol">%start Precedence
%title "Operator precedence"
%comment "Shows the handling of operator precedence in `parol`"

%%

// ---------------------------------------------------------
// VARIABLE
Variable: /(?i)[A-Z][0-9A-Z]*/
        ;
Literal : /[0-9]+/
        ;

// ---------------------------------------------------------
// OPERATOR SYMBOLS
Plus    : '+'
        ;
Minus   : '-'
        ;
MulOp   : "\*|/"
        ;

// ---------------------------------------------------------
// PARENTHESIS
LParen  : '('
        ;
RParen  : ')'
        ;

// ---------------------------------------------------------
// EXPRESSIONS in order of increasing precedence
Precedence
        : Summation
        ;
Summation
        : Multiplication { (Plus | Minus) Multiplication }
        ;
Multiplication
        : Factor { MulOp Factor }
        ;
Factor  : Literal
        | Variable
        | Minus Factor
        | LParen Precedence RParen
        ;
</code></pre>
<p>Parsing the string <code>-1 + x * 5</code> with the generated parser will create the following parse tree:</p>
<p><img src="./precedence/test.svg" alt="Parse Tree" /></p>
<blockquote>
<p>Hint: If the picture is too small please open it in a separate tab via context menu.</p>
</blockquote>
<p>Here you can see that the "inner most" operator is evaluated first by the parser, here the negation
in production <code>Factor</code>.</p>
<p>The <code>Multiplication</code> is the  second highest priority in our example. It is a sub-category of the
<code>Summation</code>.</p>
<p>You can try this grammar by calling</p>
<pre><code class="language-shell">parol new --bin --path .\precedence --tree
</code></pre>
<p>Open the generated crate and substitute the generated dummy grammar by the one above.
Also change the test.txt to the content</p>
<pre><code class="language-text">-1 + x * 5
</code></pre>
<p>Now you can parse this text by calling</p>
<pre><code class="language-shell">cargo run ./test.txt
</code></pre>
<p>from the generated crate's root folder.</p>
<p>Since we added the <code>--tree</code> flag at the <code>parol new</code> command parol generates parse trees for us.
Search for a <code>test.svg</code> file beside the <code>text.txt</code> file.</p>
<p>I advice to use the parse tree generation feature when developing your grammar and to remove it
again when putting your parser into production mode.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="operator-associativity"><a class="header" href="#operator-associativity">Operator associativity</a></h1>
<p>Operator associativity describes the "direction" in which <em><strong>operators of the same precedence</strong></em> are
evaluated.</p>
<h2 id="left-associativity"><a class="header" href="#left-associativity">Left associativity</a></h2>
<p>First let's have a look at left associativity.</p>
<p>We'll demonstrate this with a small example grammar that only supports multiplication which is left
associative, i.e. <code>x * y * z</code> is evaluated as <code>(x * y) * z</code>.</p>
<pre><code class="language-parol">%start LeftAssociativity
%title "Operator associativity"
%comment "Shows the handling of operator associativity in `parol`"

%%

Literal : /[0-9]+/
        ;

// ---------------------------------------------------------
// OPERATOR SYMBOLS
MulOp   : '*'
        ;

// ---------------------------------------------------------
// EXPRESSIONS
LeftAssociativity
        : Multiplication
        ;

Multiplication
        : Literal { MulOp Literal }
        ;
</code></pre>
<p>You can try this grammar by calling</p>
<pre><code class="language-shell">parol new --bin --path .\left_associativity --tree
</code></pre>
<p>Open the generated crate and substitute the generated dummy grammar by the one above.
Also change the <code>test.txt</code> to the content</p>
<pre><code class="language-text">5 * 6 * 2
</code></pre>
<p>Now you can parse this text by calling</p>
<pre><code class="language-shell">cargo run ./test.txt
</code></pre>
<p>from the generated crate's root folder.</p>
<p>Parsing the string <code>5 * 6 * 2</code> with the generated parser will create the following parse tree:</p>
<p><img src="./left_associativity/test.svg" alt="Parse Tree" /></p>
<blockquote>
<p>Hint: If the picture is too small please open it in a separate tab via context menu.</p>
</blockquote>
<p>Now you would say "Stop, this parse tree imposes right associativity! The expression is evaluated
from right to left".</p>
<p>This is right at the first glance but there is one thing you have to know about <code>parol</code>'s internals:</p>
<p><em><strong>If you use <code>parol</code> with auto-generation mode (flag -g) all repetitive grammar constructs are
provided as vectors in your AST types.</strong></em></p>
<p>Snippet from the generated types in <code>src/left_associativity_grammar_trait.rs</code>:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>/// Type derived for non-terminal Multiplication
pub struct Multiplication&lt;'t&gt; {
    pub literal: Box&lt;Literal&lt;'t&gt;&gt;,
    pub multiplication_list: Vec&lt;MultiplicationList&lt;'t&gt;&gt;,
}

/// Type derived for non-terminal MultiplicationList
pub struct MultiplicationList&lt;'t&gt; {
    pub mul_op: Box&lt;MulOp&lt;'t&gt;&gt;,
    pub literal: Box&lt;Literal&lt;'t&gt;&gt;,
}
<span class="boring">}</span></code></pre></pre>
<p>This means that items of a repetition (<code>{...}</code>) are stored in a vector and can be processed later in
the desired direction. I defined this behavior for all repetitions of grammar items.</p>
<p>With this explained you can figure out that it is up to your grammar processing to chose the right
direction of evaluation.</p>
<p>We will complete this explanation by implementing our example that way.</p>
<p>Therefore apply the following changes to <code>src/left_associativity_grammar.rs</code>.</p>
<p>Replace the use statements at the top of the file with the following lines:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use crate::left_associativity_grammar_trait::{
    LeftAssociativity, LeftAssociativityGrammarTrait, Literal,
};
use parol_runtime::parol_macros::{bail, parol};
use parol_runtime::Result;
use std::fmt::{Debug, Display, Error, Formatter};
<span class="boring">}</span></code></pre></pre>
<p>Add a result member to the struct <code>LeftAssociativityGrammar</code>:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct LeftAssociativityGrammar&lt;'t&gt; {
    pub left_associativity: Option&lt;LeftAssociativity&lt;'t&gt;&gt;,
    pub result: u32,
}
<span class="boring">}</span></code></pre></pre>
<p>Add the following two functions to the impl block of the struct <code>LeftAssociativityGrammar</code>:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>    fn number(literal: &amp;Literal) -&gt; Result&lt;u32&gt; {
        literal
            .literal
            .text()
            .parse::&lt;u32&gt;()
            .map_err(|e| parol!("'{}': {e}", literal.literal.text()))
    }

    fn process_operation(&amp;mut self) -&gt; Result&lt;()&gt; {
        if let Some(grammar) = &amp;self.left_associativity {
            let init = Self::number(&amp;grammar.multiplication.literal)?;
            self.result = grammar.multiplication.multiplication_list.iter().fold(
                Ok(init),
                |acc: Result&lt;u32&gt;, mul| {
                    if let Ok(mut acc) = acc {
                        acc *= Self::number(&amp;mul.literal)?;
                        Ok(acc)
                    } else {
                        acc
                    }
                },
            )?;
            Ok(())
        } else {
            bail!("No valid parse result!")
        }
    }
<span class="boring">}</span></code></pre></pre>
<p>Change the Display implementation in this way:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>impl Display for LeftAssociativityGrammar&lt;'_&gt; {
    fn fmt(&amp;self, f: &amp;mut Formatter&lt;'_&gt;) -&gt; std::result::Result&lt;(), Error&gt; {
        match &amp;self.left_associativity {
            Some(_) =&gt; writeln!(f, "{}", self.result),
            None =&gt; write!(f, "No parse result"),
        }
    }
}
<span class="boring">}</span></code></pre></pre>
<p>And finally change the last line of the function <code>left_associativity</code> at the end of the file from</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>        Ok(())
<span class="boring">}</span></code></pre></pre>
<p>to</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>        self.process_operation()
<span class="boring">}</span></code></pre></pre>
<p>And now run the parser again:</p>
<pre><code class="language-shell">$ cargo run ./test.txt
   Compiling left_associativity v0.1.0 (C:\Users\joerg\Source\temp\left_associativity)
    Finished dev [unoptimized + debuginfo] target(s) in 1.77s
     Running `target\debug\left_associativity.exe .\test.txt`
Parsing took 3 milliseconds.
Success!
60
</code></pre>
<p>Great! The parser processed the input correctly and calculated the right result: <em><strong>60</strong></em>.</p>
<p>The interesting part of the solution can be found in the function <code>process_operation</code>.
Here we simply fold the multiplication results into the <code>result</code> member. The start value of the fold
operation is the first element of the list which is represented by the member <code>literal</code> of the
struct <code>Multiplication</code>.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>/// Type derived for non-terminal Multiplication
pub struct Multiplication&lt;'t&gt; {
    pub literal: Box&lt;Literal&lt;'t&gt;&gt;,
    pub multiplication_list: Vec&lt;MultiplicationList&lt;'t&gt;&gt;,
}
<span class="boring">}</span></code></pre></pre>
<p>The struct <code>Multiplication</code> is constructed this way because of the structure of our grammar:</p>
<pre><code class="language-parol">Multiplication
        : Literal { MulOp Literal }
        ;
</code></pre>
<p>Do you see the structural equivalence?</p>
<h2 id="right-associativity"><a class="header" href="#right-associativity">Right associativity</a></h2>
<p>Let's continue with a simple example grammar that only supports potentiation which is right
associative, i.e. <code>x ^ y ^ z</code> is evaluated as <code>x ^ (y ^ z)</code>. It becomes obvious if you look at this
mathematical notation: \( {x^{y}}^{z} \)</p>
<pre><code class="language-parol">%start RightAssociativity
%title "Operator associativity"
%comment "Shows the handling of operator associativity in `parol`"

%%

Literal : /[0-9]+/
        ;

// ---------------------------------------------------------
// OPERATOR SYMBOLS
PowOp   : '^'
        ;

// ---------------------------------------------------------
// EXPRESSIONS
RightAssociativity
        : Potentiation
        ;

Potentiation
        : Literal { PowOp Literal }
        ;
</code></pre>
<p>You can try this grammar by calling</p>
<pre><code class="language-shell">parol new --bin --path .\right_associativity --tree
</code></pre>
<p>Open the generated crate and substitute the generated dummy grammar by the one above.
Also change the <code>test.txt</code> to the content</p>
<pre><code class="language-text">4 ^ 3 ^ 2
</code></pre>
<p>Now you can parse this text by calling</p>
<pre><code class="language-shell">cargo run ./test.txt
</code></pre>
<p>from the generated crate's root folder.</p>
<p>Parsing the string <code>4 ^ 3 ^ 2</code> with the generated parser will create the following parse tree:</p>
<p><img src="./right_associativity/test.svg" alt="Parse Tree" /></p>
<blockquote>
<p>Hint: If the picture is too small please open it in a separate tab via context menu.</p>
</blockquote>
<p>You'll see that the parse tree is structural identical to the one we saw above when we examined left
associativity. And you may know now that <code>parol</code> handles all repetitive constructs identical as
vectors.</p>
<p>As done before, we will complete this explanation by implementing our example.</p>
<p>So, first please make all the modification to the file <code>src/right_associativity_grammar.rs</code> as
made in our upper example. Thereby modify prefixes <code>Left</code> and <code>left_</code> to <code>Right</code> and <code>right_</code> resp.</p>
<p>Replace the function <code>process_operation</code> with this implementation.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>    fn process_operation(&amp;mut self) -&gt; Result&lt;()&gt; {
        if let Some(grammar) = &amp;self.right_associativity {
            self.result = grammar.potentiation.potentiation_list.iter().rev().fold(
                Ok(1),
                |acc: Result&lt;u32&gt;, mul| {
                    if let Ok(mut acc) = acc {
                        acc =  Self::number(&amp;mul.literal)?.pow(acc);
                        Ok(acc)
                    } else {
                        acc
                    }
                },
            )?;
            let last = Self::number(&amp;grammar.potentiation.literal)?;
            self.result = last.pow(self.result);
            Ok(())
        } else {
            bail!("No valid parse result!")
        }
    }
<span class="boring">}</span></code></pre></pre>
<p>Basically we also fold over the list of operation parts. But this time in reverse order (see
<code>.rev()</code> in the initialization of the iteration).
The start operand is this time the number <code>1</code> and the last operand is the single literal in the
struct <code>Potentiation</code>.</p>
<p>That's all.</p>
<p>And now run the parser again:</p>
<pre><code class="language-shell">$ cargo run ./test.txt
    Finished dev [unoptimized + debuginfo] target(s) in 0.20s
     Running `target\debug\right_associativity.exe .\test.txt`
Parsing took 3 milliseconds.
Success!
262144
</code></pre>
<p>Great! The parser processed the input correctly and calculated the right result: <em><strong>262144</strong></em>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="ast-generation"><a class="header" href="#ast-generation">AST generation</a></h1>
<p><code>parol</code> can be instructed to generate all types your grammar implies automatically. It therefore
analyzes all productions in your grammar.</p>
<h2 id="grammar-transformation"><a class="header" href="#grammar-transformation">Grammar transformation</a></h2>
<p>The first step is to canonicalize your grammar into a
standard format applying the following transformations.</p>
<ul>
<li>All EBNF constructs, i.e. optional elements, repetitions and groupings are substituted by
equivalent representations.
<ul>
<li>A: [B]; =&gt; A: BOpt; BOpt: B; BOpt: ;</li>
<li>A: {B}; =&gt; A: BList; BList: B BList; BList: ;</li>
<li>A: (B); =&gt; A: BGroup; BGroup: B;</li>
</ul>
</li>
<li>Alternations are propagated to multiple productions.
<ul>
<li>A: B | C; =&gt; A: B; A: C;</li>
</ul>
</li>
</ul>
<p>These transformations are applied iteratively until all EBNF constructs are replaced.</p>
<p>Note that the transformations applied on LR grammars are slightly different, but the principle is
the same.</p>
<h2 id="sanity-checks"><a class="header" href="#sanity-checks">Sanity checks</a></h2>
<p>Then <code>parol</code> checks this pre-transformed input grammar for several properties that prevent a
successful processing. Those unwanted properties are</p>
<ul>
<li>Left-recursions</li>
<li>Non-productive non-terminals</li>
<li>Unreachable non-terminals</li>
</ul>
<p>If the grammar does not have such properties the next step is to left-factor this grammar form. This
step is crucial for decreasing the number of necessary lookahead symbols.</p>
<h2 id="the-expanded-grammar"><a class="header" href="#the-expanded-grammar">The Expanded grammar</a></h2>
<p>This finally transformed grammar is the basis for the parser generation and is typically written to
file for later reference. By convention this 'expanded' grammar is stored to files named
&lt;original-name&gt;-exp.par.</p>
<p>This expanded grammar is the basis for parser generation.</p>
<h2 id="type-inference"><a class="header" href="#type-inference">Type inference</a></h2>
<p>Having such a transformed grammar all productions have the form
\[v: s*; \]
where \(v \epsilon V, s \epsilon (V \cup \Sigma)\), \(V\) is the set of non-terminals,
\(\Sigma\) is the set of terminals.</p>
<p>The relation of the generated productions to their original EBNF constructs is actually lost at this
point.</p>
<p>But because we need the information if a set of productions was originated from, e.g. an optional
construct (<code>[...]</code>) <code>parol</code>conveys these relationship during the whole transformation process to be
able to infer it into a Rust <code>Option&lt;T&gt;</code> eventually.</p>
<p>To explain it using the form of transformation shown above we could write this:</p>
<p><code>A: [B]; =&gt; A: BOpt; BOpt: B; BOpt: ; =&gt; typeof A = Option&lt;typeof B&gt;</code></p>
<p>This step leads directly to a solution if non-terminal <code>A</code> has only one production.</p>
<p>In this case the the type of <code>A</code> is</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>struct A {
    b: Option&lt;B&gt;
}
<span class="boring">}</span></code></pre></pre>
<p>We must use a <code>struct</code> here because this patterns should work for productions with \(n\)
elements on its right-hand side. For each such element we then introduce a separate member into the
struct.</p>
<p>If non-terminal <code>A</code> has more than one productions the resulting type of <code>A</code> will be a Rust <code>enum</code>
type with \(n\) enum variants for \(n\) productions, e.g.:</p>
<p><code>A: B | C; =&gt; A: B; A: C; =&gt;</code></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>struct B {
    // ...
}
struct C {
    // ...
}
// Type of non-terminal A
enum A {
    A0(B),
    A1(C),
}
<span class="boring">}</span></code></pre></pre>
<p>When finally all types for all non-terminals are inferred <code>parol</code> generates an overall AST type.
This is also a Rust <code>enum</code>. It comprises all non-terminal types of the grammar and provides exactly
one enum variant for each of them. This type is mainly used by the parser itself to be able to
instantiate a typed parse stack. The user rarely have to deal with this AST <code>enum</code>.</p>
<h3 id="recursive-structure-of-a-grammar"><a class="header" href="#recursive-structure-of-a-grammar">Recursive structure of a grammar</a></h3>
<p>A context free grammar is typically defined using recursive constructs. But you can't define types
in Rust that are directly recursive because this would lead to an infinitive type size.</p>
<p>To cope with this limitation <code>parol</code> generates boxed types for non-terminals when introducing
elements to <code>struct</code>s, e.g.:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>struct A {
    b: Box&lt;B&gt;
}
<span class="boring">}</span></code></pre></pre>
<p>This results in finite type sizes.</p>
<p>Note that <code>parol</code> has a way to minimize the use of boxed types in the generated parser.
The <code>parol</code> tool supports a new command line switch (-b, --min_boxes) that enables the minimization
of used boxes in generated data structures. The <code>parol::build::Builder</code> also provides a new method
<code>minimize_boxed_types()</code> that you can call in your build scripts.</p>
<p><code>parol</code> then determines where no recursions can occur by applying extra calculations on the
structure of the grammar.</p>
<h2 id="manage-type-generation"><a class="header" href="#manage-type-generation">Manage Type generation</a></h2>
<h3 id="omission-of-elements"><a class="header" href="#omission-of-elements">Omission of elements</a></h3>
<p>You can suffix grammar symbols (terminals and non-terminals) with a cut operator (^). This instructs
<code>parol</code> to not propagate them to the AST type, e.g.:</p>
<pre><code class="language-parol">Group: '('^ Alternations ')'^;
</code></pre>
<p>The AST type for the symbol <code>Group</code> will then only contain a member for the non-terminal
<code>Alternations</code>. The parentheses are suppressed because they have no special purpose for the grammar
processing itself.</p>
<h3 id="assigning-user-types"><a class="header" href="#assigning-user-types">Assigning user types</a></h3>
<p>You can specify a user type to be inserted into the AST structure at the place where the symbol
would otherwise had the originally generated type.
Add after a grammar symbol a colon followed by a user type name to instruct <code>parol</code> to use this type
instead. In your language implementation you have to provide fallible conversions from references of
the original generated types (<code>&amp;T</code>) to your types (<code>U</code>) by implementing the trait
<code>TryFrom&lt;&amp;T&gt; for U</code>. An examples can be found in the <code>list_auto</code> example.
You can also define aliases for the user type names by inserting as many <code>%user_type</code> directives as
you want. Then use these aliases behind the colons.</p>
<p>You may have look at example <a href="https://github.com/jsinger67/parol/blob/6800c3060bad0df033e55cf113cfd16e860a5373/examples/list_auto/list.par">list_auto</a>
that demonstrates the handling of user types.</p>
<pre><code class="language-parol">%start List
%title "A possibly empty comma separated list of integers"
%comment "A trailing comma is allowed."
%user_type Number = crate::list_grammar::Number
%user_type Numbers = crate::list_grammar::Numbers

%%

List: [Items: Numbers] TrailingComma^;
Items: Num {","^ Num};
Num: "0|[1-9][0-9]*": Number;
TrailingComma: [","^];
</code></pre>
<p>In this example grammar the terminal in the production <code>Num</code> is assigned to the user type <code>Number</code>
which in turn is a shorthand for <code>crate::list_grammar::Number</code>. Also the non-terminal <code>Items</code> is
assigned to the user type <code>Numbers</code> which in turn is a shorthand for <code>crate::list_grammar::Numbers</code>.</p>
<p>The parser generator substitutes the automatically inferred type in the type of the production by
the user provided one and the parser calls the conversion form the original type to the user type at
parse time.</p>
<p>The original type is the one of the source item in the grammar - terminal or non-terminal. Please
have a look at the generated semantic action of the internal wrapper for production 1 of the
expanded grammar <code>list-exp.par</code> which can be found in also generated traits file
<code>examples\list_auto\list_grammar_trait.rs</code>:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>    /// Semantic action for production 1:
    ///
    /// ListOpt /* Option&lt;T&gt;::Some */: Items : Numbers;
    ///
    #[parol_runtime::function_name::named]
    fn list_opt_0(&amp;mut self, _items: &amp;ParseTreeType&lt;'t&gt;) -&gt; Result&lt;()&gt; {
        let context = function_name!();
        trace!("{}", self.trace_item_stack(context));
        let items = pop_item!(self, items, Items, context);
        let list_opt_0_built = ListOpt {
            items: (&amp;items)
                .try_into()
                .map_err(parol_runtime::ParolError::UserError)?,
        };
        self.push(ASTType::ListOpt(Some(Box::new(list_opt_0_built))), context);
        Ok(())
    }
<span class="boring">}</span></code></pre></pre>
<p>At the line after the trace the original item is popped from the parse stack. It has the Rust type
<code>Items</code>:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>/// Type derived for non-terminal Items
pub struct Items {
    pub num: Box&lt;Num&gt;,
    pub items_list: Vec&lt;ItemsList&gt;,
}
<span class="boring">}</span></code></pre></pre>
<p>Then later at the construction of the <code>ListOpt</code> structure the conversion to the user's type is
called: <code>.items((&amp;items).try_into()</code>.</p>
<p>The <code>TryFrom</code> trait is provided by the user. Please see <code>examples\list_auto\list_grammar.rs</code> for
that:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>impl TryFrom&lt;&amp;Items&gt; for Numbers {
    type Error = anyhow::Error;

    fn try_from(items: &amp;Items) -&gt; std::result::Result&lt;Self, Self::Error&gt; {
        Ok(Self(items.items_list.iter().fold(
            vec![items.num.num.0],
            |mut acc, e| {
                acc.push(e.num.num.0);
                acc
            },
        )))
    }
}
<span class="boring">}</span></code></pre></pre>
<p>This is an example how non-terminal types are converted into user types.</p>
<p>The easier variant is the conversion of a terminal type (i.e. a <code>Token</code>) into a user type. You can
find an example also in <code>examples\list_auto\list_grammar.rs</code>:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>impl&lt;'t&gt; TryFrom&lt;&amp;Token&lt;'t&gt;&gt; for Number {
    type Error = anyhow::Error;

    fn try_from(number: &amp;Token&lt;'t&gt;) -&gt; std::result::Result&lt;Self, Self::Error&gt; {
        Ok(Self(number.text().parse::&lt;u32&gt;()?))
    }
}
<span class="boring">}</span></code></pre></pre>
<p>Here the scanned text of the token is accessed using the method <code>text</code> of the <code>Token</code> type that was
imported from the <code>parol_runtime</code>crate. This text is then parsed into an <code>u32</code> type and finally
wrapped into a <code>Number</code>type which is a <em>newtype</em> for <code>u32</code>.</p>
<p>By implementing <code>TryFrom</code> traits for your user type you can integrate them easily into the parse
process.</p>
<p>There exist some examples that can help to become familiar with this concept. Maybe you would like
to have a look at my rudimentary
<a href="https://github.com/jsinger67/parol/tree/main/examples/basic_interpreter">basic interpreter example</a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="vanilla-mode"><a class="header" href="#vanilla-mode">Vanilla mode</a></h1>
<p>Although the auto-generation mode (switch <code>-g</code>, <code>--auto_generate</code>) is the recommended way to use
<code>parol</code> you can alternatively work in <em>vanilla mode</em>.</p>
<p>That means that <code>parol</code> skips generating AST types for you and it generates only a trait with
semantic actions for each production of the expanded grammar instead of semantic actions for each
non-terminal.</p>
<p>This means that you gain more control although you may loose some comfort.</p>
<p>Basically it is a matter of taste what mode you use. But keep in mind that growing complexity can
have an impact on the maintainability of your software.</p>
<p>So although you may loose full speed and give up some control you obtain maintainability when using
the auto-generation mode.</p>
<p>Actually <code>parol</code> itself was build in the simple mode at the first stages of its development (before
version 0.9.3). But the implementation of new features required more and more changes in the grammar
and showed the vulnerability of the existing implementation to changes in the input grammar.</p>
<p>Anyway, this chapter is dedicated to the way <code>parol</code> functions without auto-generation.</p>
<p>You may have a look at example
<a href="https://github.com/jsinger67/parol/tree/main/examples/list">list</a> that uses the <em>vanilla mode</em> and
actually shows how easy it is to work this way.</p>
<p>We will elaborate this by implementing a list example in an alternative way.</p>
<pre><code class="language-parol">%start List
%title "A possibly empty comma separated list of integers"
%comment "A trailing comma is allowed."

%%

List: Items TrailingComma^;
Items: Num {","^ Num} | ;
Num: "0|[1-9][0-9]*";
TrailingComma: [","^];
</code></pre>
<p>Let's generate a new binary crate:</p>
<p>You can try this grammar by calling</p>
<pre><code class="language-shell">parol new --bin --path ./vanilla_list --tree
</code></pre>
<p>Open the generated crate and substitute the generated dummy grammar by the one above.
Open the build.rs and delete the line 11:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>        .enable_auto_generation()
<span class="boring">}</span></code></pre></pre>
<p>For the sake of completeness delete the <code>-g</code> from the CLI equivalent in the comment at the
beginning of <code>main</code>.</p>
<p>Also change the <code>test.txt</code> to the content</p>
<pre><code class="language-text">1, 2, 3, 4, 5, 6,
</code></pre>
<p>Now you can parse this text by calling</p>
<pre><code class="language-shell">cargo run ./test.txt
</code></pre>
<p>This will actually result in a bunch of errors because <code>parol new</code> generated the source for the new
crate in the spirit of auto-generation mode.</p>
<p>But fortunately it is easy to correct the errors and create the basis for our <em>vanilla mode</em> crate.</p>
<p>Replace the content of <code>vanilla_list_grammar.rs</code> with the following lines</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use parol_runtime::parol_macros::parol;
use parol_runtime::parser::ParseTreeType;
use parol_runtime::Result;
use std::fmt::{Debug, Display, Error, Formatter};

use crate::vanilla_list_grammar_trait::VanillaListGrammarTrait;

///
/// The value range for the supported list elements
///
pub type DefinitionRange = usize;

///
/// Data structure that implements the semantic actions for our list grammar
///
#[derive(Debug, Default)]
pub struct VanillaListGrammar {
    pub numbers: Vec&lt;DefinitionRange&gt;,
}

impl VanillaListGrammar {
    pub fn new() -&gt; Self {
        VanillaListGrammar::default()
    }

    fn push(&amp;mut self, item: DefinitionRange) {
        self.numbers.push(item)
    }
}

impl Display for VanillaListGrammar {
    fn fmt(&amp;self, f: &amp;mut Formatter&lt;'_&gt;) -&gt; std::result::Result&lt;(), Error&gt; {
        writeln!(
            f,
            "[{}]",
            self.numbers
                .iter()
                .map(|e| format!("{}", e))
                .collect::&lt;Vec&lt;String&gt;&gt;()
                .join(", ")
        )
    }
}

impl VanillaListGrammarTrait for VanillaListGrammar {}
<span class="boring">}</span></code></pre></pre>
<p>Now you should be able to run the parser</p>
<pre><code class="language-shell">$ cargo run ./test.txt
Finished dev [unoptimized + debuginfo] target(s) in 0.23s
     Running `target\debug\vanilla_list.exe .\test.txt`
Parsing took 3 milliseconds.
Success!
[]
</code></pre>
<p>Also some warnings should occur. But we resolve them soon.</p>
<p>What we see here is that the parser accepts the input but doesn't collect the list items for us
immediately (there are no list items in between <code>[</code> and <code>]</code>). The parser functions as an acceptor
but without any processing.</p>
<p>We need to do this on our own.</p>
<p>To be able to 'hook' into the right production we need to examine the expanded grammar more closely
than we had to in the auto-generation mode.</p>
<p>So open the generated file <code>vanilla_list-exp-par</code> and look for the production where a <code>Num</code> token
is accepted:</p>
<pre><code class="language-parol">/* 5 */ Num: "0|[1-9][0-9]*";
</code></pre>
<p>Then we need to implement the semantic action for exactly this production number 5. We find the
trait function to implement in the file <code>src\vanilla_list_grammar_trait.rs</code> and copy it into the
impl block at the end of the file <code>src\vanilla_list_grammar.rs</code>:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>impl VanillaListGrammarTrait for VanillaListGrammar {
    /// Semantic action for production 5:
    ///
    /// Num: "0|[1-9][0-9]*";
    ///
    fn num(&amp;mut self, _num: &amp;ParseTreeType) -&gt; Result&lt;()&gt; {
        Ok(())
    }
}
<span class="boring">}</span></code></pre></pre>
<p>Here we can implement our handling:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>    /// Semantic action for production 5:
    ///
    /// Num: "0|[1-9][0-9]*";
    ///
    fn num(&amp;mut self, num: &amp;ParseTreeType) -&gt; Result&lt;()&gt; {
        let symbol = num.text()?;
        let number = symbol
            .parse::&lt;DefinitionRange&gt;()
            .map_err(|e| parol!("num: Parse error: {e}"))?;
        self.push(number);
        Ok(())
    }
<span class="boring">}</span></code></pre></pre>
<p>Now run the parser again</p>
<pre><code class="language-shell">$ cargo run ./test.txt
    Finished dev [unoptimized + debuginfo] target(s) in 1.54s
     Running `target\debug\vanilla_list.exe .\test.txt`
Parsing took 4 milliseconds.
Success!
[1, 2, 3, 4, 5, 6]
</code></pre>
<p>Yep! This worked fine.</p>
<p>Note that you can`t use user defined types for your ATS types in vanilla mode because no AST types
are generated at all. But actually you opted in to build the AST types on your own when you disable
auto-generation mode.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="semantic-actions-1"><a class="header" href="#semantic-actions-1">Semantic actions</a></h1>
<p>The <code>parol</code> parser generator creates traits with functions that represent semantic actions.
The generated parser then calls these functions at parse time at the appropriate points with correct
arguments.</p>
<p>The generated trait for user actions (i.e. semantic actions) will be named after the following
scheme:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub trait &lt;NameOfYourGrammar&gt;GrammarTrait&lt;'t&gt; {
    // ...
}
<span class="boring">}</span></code></pre></pre>
<p>The lifetime parameter &lt;'t&gt; can be left out if the types used don't hold references to the scanned
text. This is automatically deduced.</p>
<p>Eventually your grammar processing item implements this trait and can overwrite those functions of
the trait in which it is interested in.</p>
<p>It doesn't need to implement all trait functions because the trait is created in a way where all of
its functions have default implementations.</p>
<p><code>parol</code> provides two different modes with different properties of semantic actions:</p>
<ul>
<li><a href="SemanticActions.html#semantic-actions-in-vanilla-mode">Vanilla mode</a></li>
<li><a href="SemanticActions.html#semantic-actions-in-auto-generation-mode">Auto-gen mode</a></li>
</ul>
<p><img src="ParolModes.svg" alt="Parol&#39;s Modes" />Overview of the two modes</p>
<h2 id="semantic-actions-in-vanilla-mode"><a class="header" href="#semantic-actions-in-vanilla-mode">Semantic actions in Vanilla mode</a></h2>
<p>In the less comfortable vanilla mode there are some differences we will address next.</p>
<p>The functions in the semantic actions trait correspond to the <em>productions</em> of the
<a href="AstGeneration.html#the-expanded-grammar">expanded grammar</a>. This implies that you as the user have
to look more closely at this transformed version of your original grammar and that you should have a
basic understanding of the <a href="AstGeneration.html#grammar-transformation">transformations</a> that had
been applied to it.</p>
<p>The functions' parameter then correspond to the right-hand side of the respective production.</p>
<p>To demonstrate this aspect we show an excerpt of the generated semantic actions seen in the example
from the previous chapter.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub trait VanillaListGrammarTrait {
    // ...

    /// Semantic action for production 5:
    ///
    /// Num: "0|[1-9][0-9]*";
    ///
    fn num(&amp;mut self, _num: &amp;ParseTreeType) -&gt; Result&lt;()&gt; {
        Ok(())
    }

    // ...
}
<span class="boring">}</span></code></pre></pre>
<p>This is only the semantic action for production 5:</p>
<pre><code class="language-parol">/* 5 */ Num: "0|[1-9][0-9]*";
</code></pre>
<p>The first thing you will notice is that the trait function has a default implementation. It does
nothing but returning <code>Ok</code>.</p>
<p>The second property of a all these functions is that the first argument always is a mutable
reference to the implementing item, in this case a reference to <code>VanillaListGrammar</code>.</p>
<p>The rest of the arguments correspond to the right-hand side of the respective production.</p>
<p>Next you see a concrete implementation of a semantic action, where all arguments of the semantic
action are used. This is not always necessary the case and depends on your own language
implementation.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>impl VanillaListGrammarTrait for VanillaListGrammar {
    /// Semantic action for production 5:
    ///
    /// Num: "0|[1-9][0-9]*";
    ///
    fn num(&amp;mut self, num: &amp;ParseTreeType) -&gt; Result&lt;()&gt; {
        let symbol = num.text()?;
        let number = symbol
            .parse::&lt;DefinitionRange&gt;()
            .map_err(|e| parol!("num: Parse error: {e}"))?;
        self.push(number);
        Ok(())
    }
}
<span class="boring">}</span></code></pre></pre>
<p>You can see that the parameter of the semantic actions which correspond to the right-hand side of
the respective productions are all of type <code>&amp;ParseTreeType</code>. This type from the
<a href="https://github.com/jsinger67/parol/blob/main/crates/parol_runtime/src/parser/parse_tree_type.rs">parol_runtime</a>
crate is defined this way:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>///
/// The type of the elements in the parse tree.
///
/// The lifetime parameter `'t` refers to the lifetime of the scanned text.
///
#[derive(Debug, Clone)]
pub enum ParseTreeType&lt;'t&gt; {
    ///
    /// A scanned token.
    ///
    T(Token&lt;'t&gt;),

    ///
    /// A non-terminal name.
    /// All names are of static lifetime (see NON_TERMINALS slice of non-terminal names).
    ///
    N(&amp;'static str),
}
<span class="boring">}</span></code></pre></pre>
<p>It implements two functions that you can directly call in your semantic actions:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>impl&lt;'t&gt; ParseTreeType&lt;'t&gt; {
    ///
    /// Tries to access the Token of the ParseTreeType.
    /// Can fail if the entry is no terminal (i.e. a non-terminal).
    ///
    pub fn token(&amp;self) -&gt; Result&lt;&amp;Token&lt;'t&gt;, ParserError&gt; {
        match self {
            Self::T(t) =&gt; Ok(t),
            _ =&gt; Err(ParserError::InternalError(format!("{} is no token!", self))),
        }
    }

    ///
    /// Tries to access the scanned text of the ParseTreeType.
    /// Can fail if the entry is no terminal (i.e. a non-terminal).
    ///
    pub fn text(&amp;self) -&gt; Result&lt;&amp;str, ParserError&gt; {
        match self {
            Self::T(t) =&gt; Ok(t.text()),
            _ =&gt; Err(ParserError::InternalError(format!("{} is no token!", self))),
        }
    }
}
<span class="boring">}</span></code></pre></pre>
<p>In your semantic action you exactly know which argument correspond to a terminal or a non-terminal
symbol. If you want to access the token that contains a concrete terminal you can use one of these
functions. Non-terminals are of lesser interest because non-terminals are simply nodes with the
non-terminal's name that represents certain subtrees in the concrete parse-tree. So it is worth to
consider the following hints.</p>
<p>A good way to process your grammar is to implement an own typed parse stack in your grammar
processing item. Then you construct such stack items from the tokens you encounter in your semantic
actions and push them on your parse stack. They then are something like the <em>results</em> of your
semantic actions which are collected on the parse stack for further processing. You then can access
these results of earlier semantic actions later from other semantic actions and construct the parse
result step by step using them.</p>
<p>A good demonstration of this approach can be found at the example
<a href="https://github.com/jsinger67/parol/blob/main/examples/calc/calc_grammar.rs">calc</a>.</p>
<p>The direction in which the parser derives the symbols of your grammar guarantees that when a
semantic action of a production is called all elements of the production have been processed before.
That's why you know the non-terminals are collected and lay on top of your own parse stack.</p>
<h2 id="semantic-actions-in-auto-generation-mode"><a class="header" href="#semantic-actions-in-auto-generation-mode">Semantic actions in Auto-generation mode</a></h2>
<p>The auto-gen mode abstracts away the <a href="AstGeneration.html#the-expanded-grammar">expanded version</a> of
your grammar. As in <a href="SemanticActions.html#semantic-actions-in-vanilla-mode">vanilla mode</a> the
<code>parol</code> parser generator creates a trait with functions that represent semantic actions. But here
the semantic actions are typed and they are generated for the <em>non-terminals of your input grammar</em>
instead of for <em>productions of the <a href="AstGeneration.html#the-expanded-grammar">expanded grammar</a></em>.</p>
<p>You therefore don't have to mess around with <code>ParseTreeType</code> although you still encounter items of
type <code>Token</code>. Also the expanded version of your grammar is much less of interest for you.</p>
<p><code>parol</code>'s great merit is that it can generate an adapter layer automatically that provides the
conversion to typed grammar items. Indeed I carved out some simple rules that can be applied
universally to provide this layer of abstraction by generating the production bound semantic
actions accordingly.</p>
<p>This and the automatic AST type inference are the most outstanding properties of <code>parol</code>.</p>
<p>We will use the example
<a href="https://github.com/jsinger67/parol/tree/main/examples/calc_auto">calc_auto</a> for detailed
explanations.</p>
<p>The file
<a href="https://github.com/jsinger67/parol/blob/main/examples/calc_auto/calc_grammar_trait.rs">calc_grammar_trait.rs</a>
contains the generated traits and types we are interested in.</p>
<p>First we will have a look at the <code>CalcGrammarTrait</code> at the top of this file. For each non-terminal
of the input grammar
<a href="https://github.com/jsinger67/parol/blob/main/examples/calc_auto/calc.par">calc.par</a> it contains
exactly one semantic action.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>/// Semantic actions trait generated for the user grammar
/// All functions have default implementations.
pub trait CalcGrammarTrait&lt;'t&gt; {
    /// Semantic action for non-terminal 'calc'
    fn calc(&amp;mut self, _arg: &amp;Calc&lt;'t&gt;) -&gt; Result&lt;()&gt; {
        Ok(())
    }
    // ...
}
<span class="boring">}</span></code></pre></pre>
<p>The approach taken in this example is quite interesting. We only implement the semantic action for
the start symbol of our grammar: <em>calc</em>.</p>
<p>The implementation can be found in
<a href="https://github.com/jsinger67/parol/blob/main/examples/calc_auto/calc_grammar.rs">calc_grammar.rs</a>.</p>
<p>Near the end you can find the one and only semantic action we implement here and thereby creating
the functionality of a calculator language.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>impl&lt;'t&gt; CalcGrammarTrait&lt;'t&gt; for CalcGrammar&lt;'t&gt; {
    /// Semantic action for non-terminal 'Calc'
    fn calc(&amp;mut self, arg: &amp;Calc&lt;'t&gt;) -&gt; Result&lt;()&gt; {
        self.process_calc(arg)?;
        Ok(())
    }
}
<span class="boring">}</span></code></pre></pre>
<p>But what is the advantage of implementing only the start symbols's semantic action? Well, since the
start symbol is the root node of each and every concrete parse tree we know, that the generated type
for it should comprise the complete input as the result of the parsing.</p>
<p>The key to this is the structure of the generated type <code>Calc</code>. It resembles the structure of all
productions belonging to the non-terminal `calc'. There is actually only one production for calc:</p>
<pre><code class="language-parol">calc: { instruction ";"^ };
</code></pre>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>///
/// Type derived for non-terminal calc
///
pub struct Calc&lt;'t&gt; {
    pub calc_list: Vec&lt;CalcList&lt;'t&gt;&gt;,
}
<span class="boring">}</span></code></pre></pre>
<p>The type <code>Calc</code> is basically a vector, which can be deduced from the repetition construct at the
right-hand side of the production (<code>{ instruction ";"^ }</code>).</p>
<p>The elements of the vector are of type <code>CalcList</code> that is defined this way:</p>
<blockquote>
<p>The reason why boxed types are needed is explained
<a href="AstGeneration.html#recursive-structure-of-a-grammar">here</a>.</p>
<p>Also note that in the meantime the very <code>Box</code> here could be optimized away by <code>parol</code>. This is a great example of the evolution of it.</p>
</blockquote>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>///
/// Type derived for non-terminal calcList
///
pub struct CalcList&lt;'t&gt; {
    pub instruction: Box&lt;Instruction&lt;'t&gt;&gt;,
}
<span class="boring">}</span></code></pre></pre>
<p>And in turn the type <code>Instruction</code> looks like this:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>///
/// Type derived for non-terminal instruction
///
pub enum Instruction&lt;'t&gt; {
    Assignment(InstructionAssignment&lt;'t&gt;),
    LogicalOr(InstructionLogicalOr&lt;'t&gt;),
}
<span class="boring">}</span></code></pre></pre>
<p>The latter one is an enum with two variants because the non-terminal <code>instruction</code> has two
productions:</p>
<pre><code class="language-parol">// ---------------------------------------------------------
// INSTRUCTION
instruction: assignment;
instruction: logical_or;
</code></pre>
<p>This concept is applied for all non-terminals of your grammar. Actually your grammar became
<em>typified</em>.</p>
<p>This means eventually that any variable of type <code>Calc</code> can represent a validly parsed input sentence
that belongs to the grammar defined by
<a href="https://github.com/jsinger67/parol/blob/main/examples/calc_auto/calc.par">calc.par</a>.</p>
<p>You then only have to evaluate the content of this value as done in this calculator example.
I recommend to study this example more deeply and the approach will become obvious to you.</p>
<p>As mentioned earlier the implementation can be found here:
<a href="https://github.com/jsinger67/parol/blob/main/examples/calc_auto/calc_grammar.rs">calc_grammar.rs</a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="useful-tips"><a class="header" href="#useful-tips">Useful tips</a></h1>
<h2 id="build-performance"><a class="header" href="#build-performance">Build performance</a></h2>
<p>To get an optimized build performance when using <code>parol</code>'s
<a href="https://github.com/jsinger67/parol/blob/main/crates/parol/src/build.rs">Builder</a> API in your
<code>build.rs</code> script you can insert the following overrides into your <code>Cargo.toml</code> file:</p>
<pre><code class="language-toml"># Optimized build performance
[profile.dev.build-override]
opt-level = 3

[profile.release.build-override]
opt-level = 3
</code></pre>
<h3 id="credits"><a class="header" href="#credits">Credits</a></h3>
<p>Thanks to <a href="https://github.com/dalance">dalance</a> for reporting
<a href="https://github.com/jsinger67/parol/issues/49">#49 (build.rs performance)</a></p>
<h2 id="performance-of-parser-generation"><a class="header" href="#performance-of-parser-generation">Performance of parser generation</a></h2>
<p>First you need to understand that the necessity to frequently generate the parser from a given
grammar is drastically diminished in <code>parol</code> because of its design.
That means <code>parol</code> generates besides the data structures for your grammar only an interface and the
plumping to call its methods.
This cuts the dependencies for parser generation from any code you write to process your grammar,
i.e. the interface's implementation.</p>
<blockquote>
<p>By the way, this property enables ad hoc generation of acceptors for any valid grammar, which I like
to call <em>rapid prototyping</em> for your grammar.</p>
</blockquote>
<p>So, you only need to generate the parser if you change anything in your grammar description, i.e.
in your *.par file.
If parser generation is expensive for your grammar, what indeed can be the case, I advice you to put
the generated parser and the user trait under source control.</p>
<p>The next thing you should understand is that you should design your grammar to be LL(k) with k as
minimal as possible. I know, this can be hard but will pay out in the end.</p>
<p>Also try to optimize your grammar for the goal "Minimal number of productions". This can be often
broken down to these constraints:</p>
<ul>
<li>Avoid productions that only rename a non-terminal, i.e. the ones in the form
<pre><code class="language-parol">A: B;
</code></pre>
</li>
<li>Try to disambiguate your productions, i.e. avoid duplications that have the following form
<pre><code class="language-parol">A: X Y Z;
B: X Y Z;
</code></pre>
Pin down why you need productions with identical right-hand-sides. Aren't they actually the same
and shouldn't they rather be unified?</li>
</ul>
<p>If you have a historical grammar definition that is left recursive, which in deed is possible
for instance because of the ubiquity of Yacc/Bison grammar descriptions, you should allow for extra
time and effort to convert it to a working right recursive one.</p>
<p>Or you use the opportunity to use LALR(1) grammars without having to forgo the comfort of <code>parol</code>.
Have a look at the specification of a
<a href="https://jsinger67.github.io/ParGrammar.html#defining-the-grammar-type">grammar type</a>.</p>
<p><code>parol</code> currently provides no special support for this phase except that it is able to detect left
recursions in your grammar.</p>
<p>I may provide support for parts of this problem in the future, for instance to remove direct left
recursions somehow.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="questions-and-answers"><a class="header" href="#questions-and-answers">Questions and answers</a></h1>
<h2 id="q-i-get-stack-overflow-in-compiler-generated-traits-like-drop-clone-and-debug"><a class="header" href="#q-i-get-stack-overflow-in-compiler-generated-traits-like-drop-clone-and-debug">Q: I get stack overflow in compiler generated trait's like <code>Drop</code>, <code>Clone</code> and <code>Debug</code></a></h2>
<p>A: The reason is most likely a deeply nested structure generated during parsing. There are two
advices which could lead to working solution:</p>
<ol>
<li>Avoid 'plain' recursions in your grammar like this (for LL(k) grammars):</li>
</ol>
<pre><code class="language-parol">List: ListItem List;
List: ;
ListItem: Number;
Number: /0|[1-9][0-9]*/;
</code></pre>
<p>This will generate recursive data structures like this:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub enum List&lt;'t&gt; {
    ListItemList(ListListItemList&lt;'t&gt;),
    ListEmpty(ListListEmpty),
}
pub struct ListListItemList&lt;'t&gt; {
    pub list_item: Box&lt;ListItem&lt;'t&gt;&gt;,
    pub list: Box&lt;List&lt;'t&gt;&gt;,
}
pub struct Number&lt;'t&gt; {
    pub number: Token&lt;'t&gt;, /* 0|[1-9][0-9]* */
}
<span class="boring">}</span></code></pre></pre>
<p>The recursion occurs here by containing <code>List</code> in <code>ListListItemList</code>.</p>
<p>Use instead <code>parol</code>'s own repetition construct (<code>{...}</code>), which will result in the generation of a data type
containing a vector.</p>
<pre><code class="language-parol">List: { ListItem };
ListItem: Number;
Number: /0|[1-9][0-9]*/: Number;
</code></pre>
<p>This will generate iterative data structures like this:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct List&lt;'t&gt; {
    pub list_list: Vec&lt;ListList&lt;'t&gt;&gt;,
}
pub struct ListList {
    pub list_item: Box&lt;ListItem&gt;,
}
pub struct ListItem&lt;'t&gt; {
    pub number: Box&lt;Number&lt;'t&gt;&gt;,
}
<span class="boring">}</span></code></pre></pre>
<ol start="2">
<li>Implement the problematic traits by yourself and avoid the recursion by using a loop instead.
I can't give a general advice here, but there are plenty examples out there that covers this topic
thoroughly.</li>
</ol>
<h2 id="q-i-get-strange-errors-while-commissioning-my-new-grammar-and-cant-figure-out-what-the-problem-is"><a class="header" href="#q-i-get-strange-errors-while-commissioning-my-new-grammar-and-cant-figure-out-what-the-problem-is">Q: I get strange errors while commissioning my new grammar and can't figure out what the problem is</a></h2>
<p>A: Consider the following advices</p>
<ul>
<li>Break down the problem with a least input as possible</li>
<li>Enable traces:</li>
</ul>
<p>In all projects that were generated with <code>parol new</code> the env_logger is built in. First activate all
traces. I'll show the principle in powershell because this will work on Windows as well as on Linux</p>
<pre><code class="language-powershell">$env:RUST_LOG="trace"
</code></pre>
<p>Then run your scenario and examine the output. If necessary restrict the traces further by tweaking
the RUST_LOG variable, e.g. for parser and scanner internals use this:</p>
<pre><code class="language-powershell">$env:RUST_LOG="parol_runtime=trace"
# or
$env:RUST_LOG="parol_runtime::lexer=trace"
# or
$env:RUST_LOG="parol_runtime::parser=trace"
# or
$env:RUST_LOG="parol_runtime::lr_parser=trace"
</code></pre>
<ul>
<li>Examine the traces from the beginning to pin down the first occurrence of the problem</li>
<li>Often the problems are related to wrong terminal definitions or terminal conflicts or evens
scanner state related problems, therefore
<ul>
<li>Check for token types attached to the tokens provided during parse, the numbers can be found
in the generated parser</li>
<li>Check the current scanner state and if the tokens are valid there</li>
</ul>
</li>
</ul>
<h2 id="q-i-get-warnings-in-generated-code-this-function-has-too-many-arguments"><a class="header" href="#q-i-get-warnings-in-generated-code-this-function-has-too-many-arguments">Q: I get warnings in generated code 'This function has too many arguments'</a></h2>
<p>A: Configure the builder in your <code>build.rs</code> to let <code>parol</code> generate a</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span>#![allow(clippy::too_many_arguments)]
<span class="boring">fn main() {
</span><span class="boring">}</span></code></pre></pre>
<p>line at the beginning of your generated file.</p>
<p>Add this line in the builder configuration somewhere before the call to <code>.generate_parser()</code>:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>        .inner_attributes(vec![InnerAttributes::AllowTooManyArguments])
<span class="boring">}</span></code></pre></pre>
<p>Don't forget to import the <code>InnerAttributes</code> into your <code>build.rs</code>:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use parol::{build::Builder, InnerAttributes, ParolErrorReporter};
<span class="boring">}</span></code></pre></pre>
<p>Another way to avoid this waring is to modify your grammar such that the lengths of the right-hand
sides of your productions are decreased. Therefore examine the productions that correlate to the
functions where the warnings occur. Then consider to factor out parts of the RHS into separate
productions.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="changes-in-version-2"><a class="header" href="#changes-in-version-2">Changes in version 2</a></h1>
<h2 id="new-scannerlexer-crate"><a class="header" href="#new-scannerlexer-crate">New scanner/lexer crate</a></h2>
<p>As of version 2.0 <code>parol</code> uses the brand new and self written scanner crate
<a href="https://github.com/jsinger67/scnr">scrn</a>.</p>
<h3 id="motivation"><a class="header" href="#motivation">Motivation</a></h3>
<p>The motivation for switching from <code>regex-automata</code> to <code>scnr</code> was the performance of the creation of
tokenizers out of regexes during the startup of generated parsers. For small input texts this share
of the parser runtime exceeded the share of actual parsing times by a factor of &gt;30. This meant that
for the advantage of fast parsing you had to sacrifice a lot of costs for building this efficient
scanner.</p>
<p>This doesn't mean that <code>regex-automata</code> is in any way bad, on the contrary, it is a very versatile
and valuable crate for a multitude of uses cases. It only means that the use in a lexical scanner,
where you don't need the majority of features like named and unnamed capture groups is not the
optimal decision.</p>
<p>Also <code>scnr</code> is not perfect and can't compete with <code>regex-automata</code> regarding the supported regex
features. But being able and willing to forgo some comfort opens up the opportunity to gain a lot of
speed in the phase of tokenizer creation and even during the actual scanning.</p>
<p>I can give some figures to support the claims made:</p>
<p>First for the speed of building the scanner resp. the tokenizer:</p>
<div class="table-wrapper"><table><thead><tr><th>118 terminals</th><th style="text-align: right">Version 1</th><th style="text-align: right">Version 2</th></tr></thead><tbody>
<tr><td>build scanner</td><td style="text-align: right">33ms</td><td style="text-align: right">1ms</td></tr>
</tbody></table>
</div>
<p>In both cases the same conditions are applied. The regex comprised 118 terminals.</p>
<p>Then some measurements of parsing speed.</p>
<div class="table-wrapper"><table><thead><tr><th>Input (Bytes, Tokens)</th><th style="text-align: right">Version 1</th><th style="text-align: right">Version 2</th></tr></thead><tbody>
<tr><td>549, 175</td><td style="text-align: right">0.01ms + 33ms</td><td style="text-align: right">1.2ms + 1ms</td></tr>
<tr><td>58525, 3111</td><td style="text-align: right">0.76ms + 33ms</td><td style="text-align: right">2.34ms + 1 ms</td></tr>
<tr><td>5873100, 1159200</td><td style="text-align: right">122ms + 33ms</td><td style="text-align: right">80ms + 1ms</td></tr>
</tbody></table>
</div>
<p>The added value in cells with times is the constant time to create the tokenizer, which is required
once for each call to the generated parser.</p>
<p>As you can see, <code>scnr</code> does its job well.</p>
<h3 id="impact-on-lexical-analysis"><a class="header" href="#impact-on-lexical-analysis">Impact on lexical analysis</a></h3>
<p>Since <code>scnr</code> doesn't support some regex feature which are either complicated, costly or unnecessary,
some things can't be resolved simply by the means regex crates like <code>regex-automata</code> provide.
One major feature worth mentioning is non-greediness. Lets dive in this topic with the help of an
example.</p>
<p>Let's use the commonly known block comment as our example.</p>
<p>In version 1 you would have simply used a non-greedy repetition to skip over all characters in
between the start of the comment and the end of the comment.</p>
<pre><code class="language-regexp">/\*[.\r\n]*?\*/
</code></pre>
<p>or even using <code>s</code> flag, which allows <code>.</code> to match <code>\n</code> too:</p>
<pre><code class="language-regexp">/\*(?s).*?\*/
</code></pre>
<p>In version 2 with <code>scnr</code> you can not use either of these two versions. <code>scnr</code> does not support
non-greediness and does also not support flags currently. In this regard it is in good company with
other lexer/scanner generators like Lex.</p>
<p>You can although simulate non-greediness by carefully creating your regex or by introducing new
dedicated scanner modes. Both variants are explained now.</p>
<h4 id="special-regex-design"><a class="header" href="#special-regex-design">Special regex design</a></h4>
<p>You can consider the following solution</p>
<pre><code class="language-regexp">/\*([^*]|\*[^/])*\*/
</code></pre>
<p>In this working example you explicitly restrict the portion that has to be repeated non-greedily by
suppressing the acceptance of the following regex (the end of comment part) within the repetition.</p>
<p>The above solution can be phrased like this:</p>
<blockquote>
<p>Match all characters except <code>*</code> OR a <code>*</code> NOT followed by the character <code>/</code>, where <code>*</code> is the start
of the end comment part and <code>/</code> is the next character after the start of the end comment part.</p>
</blockquote>
<p>I know that this is cumbersome and maybe sometimes not even feasible when the following part is too
complex. Therefore there exist a second approach to cope with missing non-greediness.</p>
<h4 id="scanner-modes"><a class="header" href="#scanner-modes">Scanner modes</a></h4>
<p>You can make the repetition also non-greedy by creating a second scanner mode, here named <code>COMMENT</code>.</p>
<p>This mode is entered on the <strong>comment start</strong> <code>/\*</code>, then handles all tokens inside a comment and
enters <code>INITIAL</code> mode on the <strong>comment end</strong> <code>\*/</code> again.</p>
<pre><code class="language-parol">
%start NgBlockComment
%comment "Non-greedy block comment"

%on CommentStart %enter COMMENT

%scanner COMMENT {
    %auto_newline_off
    %auto_ws_off
    %on CommentEnd %enter INITIAL
}

%%

NgBlockComment: Comments;
Comments: { Comment };
Comment: CommentStart { CommentContent } CommentEnd;
CommentStart: '/*';                 // Valid in mode INITIAL
CommentEnd: &lt;COMMENT&gt;'*/';          // Valid in mode COMMENT
CommentContent: &lt;COMMENT&gt;/[.\r\n]/; // Valid in mode COMMENT
</code></pre>
<p>The <code>CommentEnd</code> terminal has precedence over <code>CommentContent</code> simply by preceding it in the
grammar description. This way it can't be 'eaten up' by the <code>CommentContent</code> terminal.</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->

        <script>
        window.addEventListener('load', function() {
            MathJax.Hub.Register.StartupHook('End', function() {
                window.setTimeout(window.print, 100);
            });
        });
        </script>

    </div>
    </body>
</html>
